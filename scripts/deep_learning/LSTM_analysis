# LSTM MULTIVARIATE Vibration Analysis for Cantilever Rod Experiment
# This script uses ax, ay, and az as inputs to predict the future az.
# This version is adapted from the robust GRU script, using an LSTM core.

# --- Part 1: Imports ---
import copy
import sys
import os
import argparse
import random
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
from torch import optim
from torch.utils.data import DataLoader, TensorDataset
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error

# --- Part 2: The LSTM Model Definition (MODIFIED for Multivariate Input) ---
class LSTM(nn.Module):
    def __init__(self, hidden_size, in_size=3, out_size=1):
        super(LSTM, self).__init__()
        self.lstm = nn.LSTM(
            input_size=in_size,
            hidden_size=hidden_size,
            batch_first=True
        )
        self.fc = nn.Linear(hidden_size, out_size)

    def forward(self, x, h=None):
        # LSTM returns output, and a tuple of (hidden_state, cell_state)
        out, (h_out, c_out) = self.lstm(x, h)
        last_hidden_state = out[:, -1, :]
        prediction = self.fc(last_hidden_state)
        return prediction, (h_out, c_out)

# --- Part 3: Data Preparation Helper Function (MODIFIED for Multivariate Input) ---
def sliding_window_multivariate(data, window_size):
    """
    Creates input-output pairs from a multivariate time series dataset.
    The input (X) will be a window of [ax, ay, az] values.
    The output (y) will be the single next 'az' value, which captures the primary vibration.
    """
    if window_size >= len(data):
        raise ValueError(f"Window size ({window_size}) must be less than data length ({len(data)})")
    
    X, y = [], []
    for i in range(len(data) - window_size):
        feature = data[i:i + window_size]
        # The target is the 'az' value (column 2) of the step after the window
        target = data[i + window_size, 2]
        X.append(feature)
        y.append(target)
    return np.array(X), np.array(y)

# --- Part 4: Main Script Execution ---
if __name__ == "__main__":
    # --- Set seed for reproducibility ---
    seed = 42
    torch.manual_seed(seed)
    np.random.seed(seed)
    random.seed(seed)
    
    # --- Parse Command-Line Arguments ---
    parser = argparse.ArgumentParser(description="LSTM Multivariate Vibration Analysis")
    parser.add_argument('--window_size', type=int, default=64, help="Size of the sliding window")
    parser.add_argument('--lstm_hidden_size', type=int, default=32, help="Hidden size of LSTM")
    parser.add_argument('--learning_rate', type=float, default=0.001, help="Learning rate for optimizer")
    parser.add_argument('--training_epochs', type=int, default=50, help="Number of training epochs")
    parser.add_argument('--batch_size', type=int, default=32, help="Batch size for training")
    parser.add_argument('--patience', type=int, default=10, help="Patience for early stopping")
    parser.add_argument('--save_plots', action='store_true', help="Save plots to files instead of showing")
    args = parser.parse_args()

    window_size = args.window_size
    lstm_hidden_size = args.lstm_hidden_size
    learning_rate = args.learning_rate
    training_epochs = args.training_epochs
    batch_size = args.batch_size
    patience = args.patience
    save_plots = args.save_plots

    print("--- Starting LSTM MULTIVARIATE Vibration Analysis ---")

    # --- A. Load and Prepare the Dataset ---
    print(f"\n[1/6] Loading multivariate data...")
    csv_file = 'calibrated_mpu9250_data.csv'

    if not os.path.exists(csv_file):
        print(f"Warning: CSV file '{csv_file}' not found. Generating synthetic data for testing...")
        # Create synthetic data if file is missing
        t = np.linspace(0, 50, 5000)
        df = pd.DataFrame({
            'ax': 0.1 * np.sin(t * 2),
            'ay': 0.1 * np.cos(t * 2),
            'az': 2.0 * np.sin(t * 31) + 0.2 * np.random.randn(5000)
        })
    else:
        df = pd.read_csv(csv_file)

    # Validate columns
    features_to_use = ['ax', 'ay', 'az']
    if not all(col in df.columns for col in features_to_use):
        print(f"Error: CSV file must contain columns: {features_to_use}")
        sys.exit(1)

    time_series_data = df[features_to_use].values
    
    # Scale all features together for the input data (X)
    feature_scaler = MinMaxScaler()
    scaled_features = feature_scaler.fit_transform(time_series_data)
    
    # Create a separate scaler *only for the target variable 'az'* for denormalization
    az_scaler = MinMaxScaler()
    az_scaler.fit(time_series_data[:, 2].reshape(-1, 1))

    # Create windows. 'y' will be automatically scaled because it comes from 'scaled_features'.
    X, y = sliding_window_multivariate(scaled_features, window_size)
    print(f"Data prepared with {len(X)} samples.")
    
    # Reshape y for PyTorch.
    y = y.reshape(-1, 1)

    # Split data
    train_size = int(len(X) * 0.70)
    val_size = int(len(X) * 0.15)
    
    X_train, y_train = X[:train_size], y[:train_size]
    X_val, y_val = X[train_size:train_size + val_size], y[train_size:train_size + val_size]
    X_test, y_test = X[train_size + val_size:], y[train_size + val_size:]

    # Convert to PyTorch tensors
    X_train = torch.tensor(X_train, dtype=torch.float32)
    y_train = torch.tensor(y_train, dtype=torch.float32)
    X_val = torch.tensor(X_val, dtype=torch.float32)
    y_val = torch.tensor(y_val, dtype=torch.float32)
    X_test = torch.tensor(X_test, dtype=torch.float32)
    y_test = torch.tensor(y_test, dtype=torch.float32)
    
    # Create DataLoader for batch processing
    train_dataset = TensorDataset(X_train, y_train)
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_dataset = TensorDataset(X_val, y_val)
    val_loader = DataLoader(val_dataset, batch_size=batch_size)

    # --- B. Initialize Model, Optimizer, and Loss Function ---
    print(f"\n[2/6] Initializing Multivariate LSTM model...")
    model = LSTM(hidden_size=lstm_hidden_size, in_size=len(features_to_use), out_size=1)
    loss_function = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)

    # --- C. Train the Model ---
    print(f"\n[3/6] Starting training...")
    best_model_state = None
    min_val_loss = float('inf')
    patience_counter = 0
    
    for epoch in range(training_epochs):
        model.train()
        train_loss = 0.0
        for X_batch, y_batch in train_loader:
            optimizer.zero_grad()
            predictions, _ = model(X_batch)
            loss = loss_function(predictions, y_batch)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * X_batch.size(0)
        
        train_loss /= len(train_loader.dataset)
        
        model.eval()
        val_loss = 0.0
        with torch.no_grad():
            for X_batch, y_batch in val_loader:
                val_predictions, _ = model(X_batch)
                loss = loss_function(val_predictions, y_batch)
                val_loss += loss.item() * X_batch.size(0)
        
        val_loss /= len(val_loader.dataset)

        if val_loss < min_val_loss:
            min_val_loss = val_loss
            best_model_state = copy.deepcopy(model.state_dict())
            patience_counter = 0
        else:
            patience_counter += 1
            if patience_counter >= patience:
                print(f"Early stopping at epoch {epoch+1}")
                break

        if (epoch + 1) % 10 == 0:
            print(f"Epoch [{epoch+1}/{training_epochs}], Train Loss: {train_loss:.6f}, Val Loss: {val_loss:.6f}")

    # --- D. Evaluate the Best Model ---
    print("\n[4/6] Evaluating model on the test set...")
    best_model = LSTM(hidden_size=lstm_hidden_size, in_size=len(features_to_use), out_size=1)
    best_model.load_state_dict(best_model_state)
    best_model.eval()

    with torch.no_grad():
        test_predictions, _ = best_model(X_test)

    # --- E. Calculate Prediction Error for Fatigue Detection ---
    print("\n[5/6] Calculating prediction error for fatigue analysis...")
    # Denormalize using the dedicated az_scaler
    y_test_unscaled = az_scaler.inverse_transform(y_test.numpy())
    test_predictions_unscaled = az_scaler.inverse_transform(test_predictions.numpy())

    prediction_error = np.abs(y_test_unscaled - test_predictions_unscaled).squeeze()

    # Calculate metrics
    mae = mean_absolute_error(y_test_unscaled, test_predictions_unscaled)
    rmse = np.sqrt(mean_squared_error(y_test_unscaled, test_predictions_unscaled))
    print(f"Test MAE: {mae:.4f}, Test RMSE: {rmse:.4f}")

    # --- F. Plot the Results ---
    print("\n[6/6] Plotting results...")
    plt.figure(figsize=(14, 7))
    plt.plot(y_test_unscaled, label='Actual Vibration (az)', color='blue', alpha=0.7)
    plt.plot(test_predictions_unscaled, label='Predicted Vibration (az)', color='red', linestyle='--')
    plt.title('Vibration Prediction on Test Data (Multivariate LSTM)')
    plt.xlabel('Time Step')
    plt.ylabel('Acceleration (Original Scale)')
    plt.legend()
    plt.grid(True)
    if save_plots:
        plt.savefig('lstm_vibration_prediction.png')
    else:
        plt.show()
    
    plt.figure(figsize=(14, 7))
    plt.plot(prediction_error, label='Prediction Error (Absolute)', color='green')
    plt.title('Prediction Error Over Time (Fatigue Indicator)')
    plt.xlabel('Time Step (in the test set)')
    plt.ylabel('Absolute Prediction Error')
    plt.legend()
    plt.grid(True)
    if save_plots:
        plt.savefig('lstm_prediction_error.png')
    else:
        plt.show()

